# DigitalHuman-survey
我们调研了数字人相关的论文、项目、国内外现状等，并对各方面调研、资料进行了整合和归纳。

# Speak From Heart: 基于情感引导的LLM多模态对话生成方法

![image](https://github.com/user-attachments/assets/4582a223-9e19-4a0b-874c-b5732a4d2a9f)

## 简介
本论文提出了 **ELMD**（Emotion-Guided LLM-Based Multimodal Dialogue），一种基于大语言模型（LLM）的情感引导多模态对话框架。ELMD通过融合文本和视觉线索，显著提升了对话系统的情感表达能力，能够生成更具情感共鸣且贴近人类的自然对话内容，解决了传统情感对话生成中的诸多局限性。

## 方法
ELMD框架主要由以下三个核心模块组成：
1. **情感检索模块（ERM）：** 使用对比学习获取细粒度的情感表示，为生成示例提供语义和情感相关内容。
2. **情感预测模块（REP）：** 将视觉信息中的情感线索与生成的响应关联起来，增强情感理解能力。
3. **情感增强响应生成模块（EERG）：** 融合多模态输入，生成流畅且富有情感的对话内容。

通过两阶段训练策略，ELMD能够捕捉细腻情感并实现多模态信息的高效协同。

## 实验结果
在两个真实场景的中文多模态数据集（M3ED 和 MMED）上进行的实验表明，ELMD在 BLEU、METEOR、ROUGE 等评价指标上显著优于现有基线模型（如 VisualGLM 和 DialoGPT），模型展现了在情感表达和语境理解方面的强大性能。

---
